{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Descriptive Statistics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Handy Dandy Import Statements to Start Off Our Handy Dandy Little Tutorial\n",
    "from scipy import stats\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point in our course, we've had plenty of time, experience, and practice in manipulating our data. \n",
    "\n",
    "However, to really _understand_ our data and underlying patterns across it, we need to dive a layer deeper into the mathematics behind data mechanics and dynamics.\n",
    "\n",
    "In order to be able to draw conclusions from our data, we need to be able to **describe and interpret our data**.\n",
    "\n",
    "This will become essential for more advanced data science concepts in data visualization, machine learning, and deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics involves collecting, interpreting, describing behaviors, and inferring trends across data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generally describe the realm of _statistics_ to be broken up into **two** major fields:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Descriptive Statistics\n",
    "\n",
    "Descriptive Statistics involves describing, presenting, summarizing and organizing your data (population-based), either through numerical calculations or data visualization methods (e.g. graphs, tables). \n",
    "\n",
    "### 2. Inferential Statistics\n",
    "\n",
    "Inferential Statistics allows us to infer trends and make assumptions/assertions about a population based on a study of a sample taken from it. \n",
    "\n",
    "Generally, the more inferential a statistical analysis becomes, the deeper and more complex we get with our mathematics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point in the course, we'll be focusing primarily on descriptive statistics in order to describe patterns, trends, distributions, and behaviors across our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a dive into applying descriptive statistics to explain our data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Central Tendency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, we often find that describing data by \"averages\" allows us to more often make more powerful assertions regarding the data as a whole. \n",
    "\n",
    "We often use **three key measures of central tendency** to help describe the centroid (arithmetic mean trend across a distribution) of our data:\n",
    "- **Mean**\n",
    "- **Median**\n",
    "- **Mode**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mean is the raw average value across our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the mean is simple: _compute the sum of all values across our data and divide by the total number of values in our dataset_.\n",
    "\n",
    "We've been using the mean for years and years, but such a surprisingly simple arithmetic calculation turns out to have massive implications across being able to critically understand and break down complex datasets! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Write a function to compute the mean from an arbitrary dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1, 3, 5, 2, 3, 7, 8, 4, 10, 0, 6, 7, 3, 0, 3, 0, 5, 7, 10, 1, 4, 9, 3])\n",
    "\n",
    "# TODO: Complete this function by having the function return the average value of our dataset.\n",
    "def compute_mean(dataset):\n",
    "    \"\"\" Main function that calculates the average value across our data. \"\"\"\n",
    "    return\n",
    "\n",
    "compute_mean(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The median is the \"middle value\" or midpoint across our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the median is as simple as it sounds: _ascertain the data value lying in the exact middle of our dataset_.\n",
    "\n",
    "One critical exception occurs when our data has an even number of values and thus has **two values** at its center: _in these cases, ascertain the **mean** value of the two medians to obtain the true median across our data_. \n",
    "\n",
    "And remember: the median can only be calculated across _sorted data_!\n",
    "\n",
    "If data is distributed in a non-normal manner, then we can learn a great deal from interpreting what the exact median value of our dataset is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Write a function to compute the median from an arbitrary dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1, 3, 5, 2, 3, 7, 8, 4, 10, 0, 6, 7, 3, 0, 3, 0, 5, 7, 10, 1, 4, 9, 3])\n",
    "\n",
    "# TODO: Complete this function by having the function return the exact true median value of our dataset.\n",
    "# HINT: Consider using DataFrame slicing to help with identifying the correct median value(s).\n",
    "def compute_median(dataset):\n",
    "    \"\"\" Main function that determines the median value across our data. \"\"\"\n",
    "    count = len(dataset)\n",
    "    \n",
    "    if count < 1:\n",
    "        # TODO: Complete this if-statement\n",
    "        return\n",
    "    if count % 2 == 1:\n",
    "        # TODO: Complete this if-statement\n",
    "        return\n",
    "    else:\n",
    "        # TODO: Complete this if-else statement\n",
    "        return\n",
    "    \n",
    "compute_median(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mode is the most commonly occurring value or feature across our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the mode is relatively simple: _find the value that occurs most frequently across our data_.\n",
    "\n",
    "Remember that if all values across our data are unique and only occur once, then our data **has no mode**!\n",
    "\n",
    "The mode is also an interesting measure of central tendency in that it can be applied towards categorical (non-numerical) data; one can find frequently occurring categories without running any calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Write a function to compute the mode from an arbitrary dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Tricker than it looks!\n",
    "data = np.array([1, 3, 5, 2, 3, 7, 8, 4, 10, 0, 6, 7, 3, 0, 3, 0, 5, 7, 10, 1, 4, 9, 3])\n",
    "\n",
    "# TODO: Complete this function by having the function return the relative mode across our dataset.\n",
    "# HINT: Remember histograms and tokenization from CS 1.2? How many they help you here? \n",
    "def compute_mode(dataset):\n",
    "    \"\"\" Main function that determines the mode value across our data. \"\"\"\n",
    "    return\n",
    "\n",
    "compute_mode(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have it!\n",
    "\n",
    "Three measures of central tendency that are critically important to understanding the distribution of our data. \n",
    "\n",
    "In future classes on distributions and introductory inferential statistics, we'll talk more about exactly **why** these measures are so important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Relative Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative positional statistics is slightly different than our friends in the central tendency community, in that they do the complete opposite than what central tendency statistics do!\n",
    "\n",
    "We see that *measures of central tendency* describe our data as a whole as per central data points.\n",
    "\n",
    "We also see that *measures of relative position* describe our data very specifically, using relative data points to partition and divide up our data for internal investigation!\n",
    "\n",
    "In this course, there are **two key measures of relative position** that we are mainly worried about:\n",
    "- **Percentile**\n",
    "- **Quartile**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The percentile is the value across your dataset below which a given percentage of data points fall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, your percentile is a value between 0 and 100 that tells you what percentage of your data is **to the left** of your percentile line.\n",
    "\n",
    "For measures of relative position, we see that it's very helpful to visually depict what we're talking about!\n",
    "\n",
    "Let's take a look at how a percentile looks across our data with an example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*Nu_ZqWswZ0YxxFpBwk7vYA.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a great example explaining percentiles in a visually pleasing manner (that we *totally* did not find and steal from Google Images). \n",
    "\n",
    "In this example, we see that percentile is not necessarily a direct value from our data. \n",
    "\n",
    "Rather, a percentile represents an **index** from 0 to 100 that partitions our data into a proportionate amount based on the value of the index. \n",
    "\n",
    "We've actually been using percentile indices all our lives.\n",
    "\n",
    "In school, we measure student skill levels in assessments/courses by measuring who fell into the top percentiles (99th, 90th, 80th, etc.).\n",
    "\n",
    "Fortune 500 companies often fall into the top percentiles for company revenue/performance.\n",
    "\n",
    "Biometric health data that is commonly used – like BMI, height, weight, etc. – are often measured with respect to the average data across people your age so that they can accurately depict what your percentile is!\n",
    "\n",
    "All these measurements are done with one purpose in mind: **to describe where a specific data point falls relative to the population**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Use the functions below to answer the following questions regarding percentiles for an arbitrary dataset._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Since the values that our data contains range from [0, 10], you may realize that most of the question answers are pretty obvious.\n",
    "\n",
    "The point here is to test that you can see how and why you can attain the percentile value given a data point across a dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1, 3, 5, 2, 3, 7, 8, 4, 10, 0, 6, 7, 3, 0, 3, 0, 5, 7, 10, 1, 4, 9, 3])\n",
    "\n",
    "# NOTE: Use this completed percentile-from-value function to calculate the percentile given a data value.\n",
    "# NOTE: Remember, the percentile indicates how much data lies to the LEFT of the associated value!\n",
    "def compute_percentile_from_value(dataset, value):\n",
    "    \"\"\" Main function that determines the percentile given a single value within a dataset. \"\"\"\n",
    "    abs_min, abs_max = dataset[0], dataset[-1]\n",
    "    return 100 * (float(value - abs_min) / (abs_max - abs_min))\n",
    "\n",
    "# TODO: Uncomment this line to run our function and answer the questions below!\n",
    "# compute_percentile_from_value(sorted(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What percentile is the value 3.5 at? \n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- What percentile is at the value 9.8?\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- What percentage of data is contained between the values 6.0 and 7.5?\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- How much data is below the value at 2.7?\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- How much data is above the value at 4.5?\n",
    "\n",
    "`Write your response here!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same thing, but in the other direction.\n",
    "\n",
    "Let's figure out data values given percentile indices across our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1, 3, 5, 2, 3, 7, 8, 4, 10, 0, 6, 7, 3, 0, 3, 0, 5, 7, 10, 1, 4, 9, 3])\n",
    "\n",
    "# NOTE: Use this completed value-from-percentile function to calculate the value given a set percentile.\n",
    "# NOTE: You may notice some unexpected percentile values returned. Why do you think that is? \n",
    "def compute_value_from_percentile(dataset, percentile, key=lambda X:X):\n",
    "    \"\"\" Main function that determines the data value given a percentile across a dataset. \"\"\"\n",
    "    rel_pos = percentile * (len(dataset) - 1)\n",
    "    floor, ceil = math.floor(rel_pos), math.ceil(rel_pos)\n",
    "    if floor == ceil:\n",
    "        return key(dataset[int(rel_pos)])\n",
    "    data0 = key(dataset[int(floor)]) * (ceil - rel_pos)\n",
    "    data1 = key(dataset[int(ceil)]) * (rel_pos - floor)\n",
    "    return data0 + data1\n",
    "    \n",
    "# TODO: Uncomment this line to run our function and answer the questions below!\n",
    "# compute_value_from_percentile(sorted(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What value is at the 40th percentile?\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- What value is at the 77th percentile?\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- How much data is contained within the 50th and 60th percentile?\n",
    "\n",
    "`Write your response here!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!\n",
    "\n",
    "We can see that this can get real complex, real fast! \n",
    "\n",
    "Percentiles can tell us a lot about our data's distribution and how we should handle values scattered across our data!\n",
    "\n",
    "In future classes, we'll work further with using percentiles to extract even more insights from our data!\n",
    "\n",
    "Now, let's quickly look at **quartiles**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The quartile is one of several values that partition your dataset into four equal parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a special type of percentile value that measures the 25%, 50%, 75%, and 100% points across your data. \n",
    "\n",
    "Like percentiles, each quartile index depicts the value by which some set amount of data lies below. \n",
    "\n",
    "For example, at the 25% quartile mark, we know that exactly 25% of our data falls below that value. \n",
    "\n",
    "Let's take a look at an illustrated example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.mathematics-monster.com/images3/quartiles_cut_offs.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we can clearly see that the lower quartile `Q1` marks where 25% of our data lies, while the middle quartile `Q2` marks where half of our data lies and the upper quartile `Q3` marks where 75% of our data lies.\n",
    "\n",
    "We also can see that the middle quartile actually represents the median value of our data.\n",
    "\n",
    "That is, where the median lies, we can assume that 50% of our data lies below and 50% of our data falls above. \n",
    "\n",
    "(But we already knew that!)\n",
    "\n",
    "We can also intuit that the minimum value of our data marks the 0th percentile and quartile (since no data falls below it) and the maximum value of our data marks the 100th percentile and quartile (since all of our data falls below it)!\n",
    "\n",
    "### _Use the two functions above to ascertain the values at the 25th, 50th, and 75th Quartile Indices._\n",
    "\n",
    "Since you've already gotten good enough practice identifying percentile values across a dataset, there's not much point to writing another function for quartile identification. \n",
    "\n",
    "Let's use the tools we already have! \n",
    "\n",
    "- 25th Quartile Value (Lower, Q1):\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- 50th Quartile Value (Median, Q2):\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- 75th Quartile Value (Upper, Q3):\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "Once you're done, let's move on to studying some more advanced measures of data distribution in our data! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Spread and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like our friends in the central tendency community, measures of spread and variance do their best to describe patterns across our data as a whole.\n",
    "\n",
    "However, unlike measures of central tendency, which focus on the distribution of our data towards an arithmetic centroid, measures of spread and variance talk about the shape and layout of our data all across the board!\n",
    "\n",
    "In this course, there are **two key measures of spread and variance** to help describe the shape of our data:\n",
    "- **Range**\n",
    "- **Standard Deviation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The range is the coordinate pair describing the smallest and largest values our data contains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, determining the range is as simple as quantifying the absolute minimum and maximum values across our data and shoving them into a coordinate object!\n",
    "\n",
    "You're probably intimately familiar with the `range()` object in Python: we're kind of constructing that for any dataset! \n",
    "\n",
    "Keep in mind that we want the **absolute** min and max: not the _local_ min and max. \n",
    "\n",
    "In other words, we don't want just any small and large value – we want the absolutely smallest and largest values that occur in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Write a function to compute the range from an arbitrary dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([1, 3, 5, 2, 3, 7, 8, 4, 10, 0, 6, 7, 3, 0, 3, 0, 5, 7, 10, 1, 4, 9, 3])\n",
    "\n",
    "# TODO: Complete this function by having the function return the effective range of values across our data.\n",
    "def compute_range(dataset):\n",
    "    \"\"\" Main function that determines the range of values across our data. \"\"\"\n",
    "    return ()\n",
    "\n",
    "compute_range(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The standard deviation is the square root of the variance and dispersion of our data from the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the standard deviation is slightly more complex than our other descriptive statistics.\n",
    "\n",
    "To calculate the standard deviation, we must first _calculate the **variance** of our data and then take its square root_. \n",
    "\n",
    "And to calculate the variance, we must _find the difference between every data point and the true mean, square the difference, sum all the differences up, and take the average of all those numbers_.\n",
    "\n",
    "The standard deviation is slightly more complicated because it has to do more with the relationship between how spread out our data is from each other and how spread out our data is from the mean. \n",
    "\n",
    "Therefore, the standard deviation allows us to _interpret individual data values and whether or not they are a considerable distance from the mean away from the rest of our data_!\n",
    "\n",
    "This becomes incredibly important when we dive into outlier detection, hypothesis testing, and analyzing data for values that may affect it abnormally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Write a function to compute the standard deviation from an arbitrary dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([1, 3, 5, 2, 3, 7, 8, 4, 10, 0, 6, 7, 3, 0, 3, 0, 5, 7, 10, 1, 4, 9, 3])\n",
    "\n",
    "# TODO: Complete this function by having the function return the standard deviation of our data.\n",
    "# NOTE: Since we need the true mean across our data, let's use our previously written function!\n",
    "def compute_standard_deviation(dataset):\n",
    "    \"\"\" Main function that approximates the standard deviation of our data. \"\"\"\n",
    "    true_mean = compute_mean(dataset)\n",
    "    \n",
    "    # TODO: Complete these calculations step-by-step to correct the standard deviation calculation.\n",
    "    sum_diffs_squared = int()\n",
    "    variance = int()\n",
    "    \n",
    "    return math.sqrt(variance)\n",
    "\n",
    "compute_standard_deviation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent!\n",
    "\n",
    "We'll work on more examples of applying these descriptive statistics over the next several weeks, allowing you to see more of how and why these measures can allow us to extract more insights from our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...by the way, there is one little thing worth mentioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python has everything you need for descriptive statistics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right!\n",
    "\n",
    "All the functions we built are useful to understand the structure of these descriptors, but we certainly don't need to write them from scratch. \n",
    "\n",
    "Python has all these methods built internally!\n",
    "\n",
    "To be more precise, we can use the libraries **NumPy** and **SciPy** to get all these descriptive statistics in a much easier manner!\n",
    "\n",
    "We have all the tools we need right here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Write a function to compute all descriptive statistics for an arbitrary dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean of our data is None.\n",
      "\n",
      "The median of our data is None.\n",
      "\n",
      "The mode of our data is None.\n",
      "\n",
      "The quartiles of our data are at the data points None, None, and None, respectively.\n",
      "\n",
      "The standard deviation of our data is None.\n"
     ]
    }
   ],
   "source": [
    "data = np.array([1, 3, 5, 2, 3, 7, 8, 4, 10, 0, 6, 7, 3, 0, 3, 0, 5, 7, 10, 1, 4, 9, 3])\n",
    "\n",
    "# TODO: Complete this function by having the function return all descriptive statistics needed using NumPy and SciPy.\n",
    "# NOTE: Range is super simple to calculate with vanilla Python and is thus not required here. \n",
    "def compute_descriptive_statistics(dataset):\n",
    "    \"\"\" Main function that calculates descriptive statistics across our dataset. \"\"\"\n",
    "    # TODO: Calculate the mean of our data using NumPy.\n",
    "    mean = None\n",
    "    \n",
    "    # TODO: Determine the median of our data using NumPy.\n",
    "    median = None\n",
    "    \n",
    "    # TODO: Determine the mode of our data using SciPy's Stats module.\n",
    "    mode = None\n",
    "    \n",
    "    # TODO: Calculate the quartile values using NumPy.\n",
    "    q1, q2, q3 = None, None, None\n",
    "    \n",
    "    # TODO: Determine the standard deviation of our data using NumPy.\n",
    "    std_dev = None\n",
    "    \n",
    "    return mean, median, mode, q1, q2, q3, std_dev\n",
    "\n",
    "mean, median, mode, q1, q2, q3, std_dev = compute_descriptive_statistics(data)\n",
    "print(\"\\nThe mean of our data is {}.\".format(mean))\n",
    "print(\"\\nThe median of our data is {}.\".format(median))\n",
    "print(\"\\nThe mode of our data is {}.\".format(mode))\n",
    "print(\"\\nThe quartiles of our data are at the data points {}, {}, and {}, respectively.\".format(q1, q2, q3))\n",
    "print(\"\\nThe standard deviation of our data is {}.\".format(std_dev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
